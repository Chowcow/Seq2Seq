{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the default tensor type at the top\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else \n",
    "                              torch.FloatTensor)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144348\n"
     ]
    }
   ],
   "source": [
    "#Import text data, Alice in Wonderland from local directory\n",
    "path = \"./aiw.txt\"\n",
    "\n",
    "text= open(path).read()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, ‘and what is the use of a book,’ thought Alice ‘without pictures or\\nconversations?’\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain w'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The vocabulary is all the unique symbols used in the text. This is the benefit of \n",
    "working with a character level RNN.\"\"\"\n",
    "\n",
    "chars = sorted(set(text))\n",
    "vocab_size= len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " '*': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " ';': 10,\n",
       " '?': 11,\n",
       " 'A': 12,\n",
       " 'B': 13,\n",
       " 'C': 14,\n",
       " 'D': 15,\n",
       " 'E': 16,\n",
       " 'F': 17,\n",
       " 'G': 18,\n",
       " 'H': 19,\n",
       " 'I': 20,\n",
       " 'J': 21,\n",
       " 'K': 22,\n",
       " 'L': 23,\n",
       " 'M': 24,\n",
       " 'N': 25,\n",
       " 'O': 26,\n",
       " 'P': 27,\n",
       " 'Q': 28,\n",
       " 'R': 29,\n",
       " 'S': 30,\n",
       " 'T': 31,\n",
       " 'U': 32,\n",
       " 'V': 33,\n",
       " 'W': 34,\n",
       " 'X': 35,\n",
       " 'Y': 36,\n",
       " 'Z': 37,\n",
       " '[': 38,\n",
       " ']': 39,\n",
       " '_': 40,\n",
       " 'a': 41,\n",
       " 'b': 42,\n",
       " 'c': 43,\n",
       " 'd': 44,\n",
       " 'e': 45,\n",
       " 'f': 46,\n",
       " 'g': 47,\n",
       " 'h': 48,\n",
       " 'i': 49,\n",
       " 'j': 50,\n",
       " 'k': 51,\n",
       " 'l': 52,\n",
       " 'm': 53,\n",
       " 'n': 54,\n",
       " 'o': 55,\n",
       " 'p': 56,\n",
       " 'q': 57,\n",
       " 'r': 58,\n",
       " 's': 59,\n",
       " 't': 60,\n",
       " 'u': 61,\n",
       " 'v': 62,\n",
       " 'w': 63,\n",
       " 'x': 64,\n",
       " 'y': 65,\n",
       " 'z': 66,\n",
       " '‘': 67,\n",
       " '’': 68,\n",
       " '“': 69,\n",
       " '”': 70}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{c:i for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionaries from character --> index and index --> character\n",
    "c_to_idx= {c:i for i, c in enumerate(chars)}\n",
    "idx_to_c= {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convert whole text to indicies. Want each character to be \\nrepresented by its index in the vocabulary. This is how we will feed to RNN'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Convert whole text to indicies. Want each character to be \n",
    "represented by its index in the vocabulary. This is how we will feed to RNN\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 19, 12, 27, 31, 16, 29, 1, 20, 8]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_idx = [c_to_idx[c] for c in text]\n",
    "text_len = len(text_idx)\n",
    "text_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on t\n",
      "--------\n",
      "t-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on t\n"
     ]
    }
   ],
   "source": [
    "#Check it works to convert back : join up the indicies\n",
    "\n",
    "print(text[25:100])\n",
    "print(\"--------\")\n",
    "print(''.join([idx_to_c[i] for i in text_idx[25:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataLoader\n",
    "#Sequence of characters passed to RNN at a time. This dictates the length of the unrolled model (#timesteps)\n",
    "#Batch size affects splitting of raw data as well as model architecture\n",
    "\n",
    "seq_len = 8\n",
    "batch_size= 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wnat a non-overlapping set of inputs and outputs. Each X should be equal to the sequence length, while the Y, shifted by 1. Note that we don't go to the end for Y.\n",
    "\n",
    "idx_in_data = [text_idx[idx:idx+seq_len] for idx in range(0, text_len-1-seq_len,seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18043, 8)\n",
      "[[14 19 12 27 31 16 29  1]\n",
      " [20  8  1 15 55 63 54  1]\n",
      " [60 48 45  1 29 41 42 42]]\n"
     ]
    }
   ],
   "source": [
    "#Convert these inputs into a numpy array and provide info. Note dimensions are the total number of sequences in the corpus and the sequence length.\n",
    "\n",
    "inp = np.array(idx_in_data)\n",
    "print(inp.shape)\n",
    "print(inp[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the samething with Y\n",
    "\n",
    "idx_out_data = [text_idx[idx:idx+seq_len] for idx in range(1, text_len-seq_len, seq_len)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18043, 8)\n",
      "[[19 12 27 31 16 29  1 20]\n",
      " [ 8  1 15 55 63 54  1 60]\n",
      " [48 45  1 29 41 42 42 49]]\n"
     ]
    }
   ],
   "source": [
    "#Confirm that the target array is the input array shifted by 1. We'll be predicting the next character in sequence.\n",
    "\n",
    "outp = np.array(idx_out_data)\n",
    "print(outp.shape)\n",
    "print(outp[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split up the input and target data into training and test sets.\n",
    "Return 4 numpy arrays- training input, training targets, test input, and test targets'''\n",
    "\n",
    "def train_test_split(inp_data, out_data, train_fraction):\n",
    "    trn_idx = np.random.rand(len(inp_data)) < train_fraction\n",
    "    \n",
    "    inp_trn = inp_data[trn_idx]\n",
    "    inp_test = inp_data[~trn_idx]\n",
    "    \n",
    "    outp_trn= out_data[trn_idx]\n",
    "    outp_test= out_data[~trn_idx]\n",
    "    return inp_trn, outp_trn, inp_test, outp_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into 90%training, 10% test. This ratio should be bigger with a larger corpus.\n",
    "\n",
    "x_trn, y_trn, x_val, y_val = train_test_split(inp,outp, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PyTorch Dataset class for character level text generation. X and Y have widt'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
